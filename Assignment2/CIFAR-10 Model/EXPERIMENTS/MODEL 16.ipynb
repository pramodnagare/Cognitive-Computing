{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EXPERIMENT+16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "o_SwyVZcMjur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1983
        },
        "outputId": "bd66ad18-a2f5-4271-9d3a-fbb914022fe7"
      },
      "cell_type": "code",
      "source": [
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Conv2D, MaxPooling2D, Dense, Flatten,Dropout,Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import SGD \n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "\n",
        "print('Shape of training dataset :',x_train.shape)\n",
        "print('Shape of testing dataste :' ,x_test.shape)\n",
        "\n",
        "#formatting the dataset \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),input_shape=[32,32,3],kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.0005),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(256,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3),kernel_regularizer=regularizers.l2(0.0005),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(512,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(512,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(512,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "SGD = SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='SGD',metrics=['accuracy'])\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip = False)\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) / 128, epochs=50,\n",
        "                    validation_data = (x_test,y_test))\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of training dataset : (50000, 32, 32, 3)\n",
            "Shape of testing dataste : (10000, 32, 32, 3)\n",
            "Epoch 1/50\n",
            "391/390 [==============================] - 127s 326ms/step - loss: 3.2773 - acc: 0.2279 - val_loss: 3.8185 - val_acc: 0.1035\n",
            "Epoch 2/50\n",
            "391/390 [==============================] - 97s 248ms/step - loss: 2.6626 - acc: 0.3147 - val_loss: 3.8695 - val_acc: 0.1257\n",
            "Epoch 3/50\n",
            "391/390 [==============================] - 101s 260ms/step - loss: 2.5084 - acc: 0.3474 - val_loss: 3.8086 - val_acc: 0.1663\n",
            "Epoch 4/50\n",
            "391/390 [==============================] - 93s 238ms/step - loss: 2.4096 - acc: 0.3767 - val_loss: 3.9307 - val_acc: 0.1033\n",
            "Epoch 5/50\n",
            "391/390 [==============================] - 101s 259ms/step - loss: 2.3427 - acc: 0.4003 - val_loss: 3.5159 - val_acc: 0.1752\n",
            "Epoch 6/50\n",
            "391/390 [==============================] - 101s 257ms/step - loss: 2.2763 - acc: 0.4237 - val_loss: 3.7446 - val_acc: 0.1872\n",
            "Epoch 7/50\n",
            "391/390 [==============================] - 101s 258ms/step - loss: 2.2111 - acc: 0.4553 - val_loss: 4.0620 - val_acc: 0.1430\n",
            "Epoch 8/50\n",
            "391/390 [==============================] - 91s 233ms/step - loss: 2.1683 - acc: 0.4615 - val_loss: 4.0587 - val_acc: 0.1757\n",
            "Epoch 9/50\n",
            "391/390 [==============================] - 102s 262ms/step - loss: 2.1302 - acc: 0.4792 - val_loss: 3.9991 - val_acc: 0.1196\n",
            "Epoch 10/50\n",
            "391/390 [==============================] - 101s 259ms/step - loss: 2.1082 - acc: 0.4927 - val_loss: 3.4909 - val_acc: 0.2351\n",
            "Epoch 11/50\n",
            "391/390 [==============================] - 99s 252ms/step - loss: 2.0577 - acc: 0.5072 - val_loss: 4.0691 - val_acc: 0.1518\n",
            "Epoch 12/50\n",
            "391/390 [==============================] - 92s 236ms/step - loss: 2.0328 - acc: 0.5173 - val_loss: 3.5999 - val_acc: 0.2169\n",
            "Epoch 13/50\n",
            "391/390 [==============================] - 98s 251ms/step - loss: 1.9797 - acc: 0.5392 - val_loss: 3.9511 - val_acc: 0.1394\n",
            "Epoch 14/50\n",
            "391/390 [==============================] - 100s 255ms/step - loss: 1.9672 - acc: 0.5428 - val_loss: 3.4884 - val_acc: 0.1862\n",
            "Epoch 15/50\n",
            "391/390 [==============================] - 104s 265ms/step - loss: 1.9422 - acc: 0.5476 - val_loss: 3.4018 - val_acc: 0.2399\n",
            "Epoch 16/50\n",
            "391/390 [==============================] - 97s 247ms/step - loss: 1.9154 - acc: 0.5519 - val_loss: 3.2260 - val_acc: 0.2270\n",
            "Epoch 17/50\n",
            "391/390 [==============================] - 103s 264ms/step - loss: 1.8762 - acc: 0.5714 - val_loss: 3.5728 - val_acc: 0.1905\n",
            "Epoch 18/50\n",
            "391/390 [==============================] - 105s 270ms/step - loss: 1.8577 - acc: 0.5770 - val_loss: 3.3974 - val_acc: 0.2604\n",
            "Epoch 19/50\n",
            "391/390 [==============================] - 107s 272ms/step - loss: 1.8147 - acc: 0.5926 - val_loss: 3.7306 - val_acc: 0.1806\n",
            "Epoch 20/50\n",
            "391/390 [==============================] - 95s 243ms/step - loss: 1.8068 - acc: 0.5934 - val_loss: 3.4923 - val_acc: 0.2016\n",
            "Epoch 21/50\n",
            "391/390 [==============================] - 103s 264ms/step - loss: 1.7847 - acc: 0.6021 - val_loss: 3.4247 - val_acc: 0.2580\n",
            "Epoch 22/50\n",
            "391/390 [==============================] - 104s 267ms/step - loss: 1.7633 - acc: 0.6091 - val_loss: 3.5093 - val_acc: 0.2461\n",
            "Epoch 23/50\n",
            "391/390 [==============================] - 104s 265ms/step - loss: 1.7410 - acc: 0.6181 - val_loss: 3.6775 - val_acc: 0.1757\n",
            "Epoch 24/50\n",
            "391/390 [==============================] - 97s 248ms/step - loss: 1.7276 - acc: 0.6198 - val_loss: 3.5125 - val_acc: 0.2186\n",
            "Epoch 25/50\n",
            "391/390 [==============================] - 105s 270ms/step - loss: 1.7215 - acc: 0.6249 - val_loss: 3.4976 - val_acc: 0.2512\n",
            "Epoch 26/50\n",
            "391/390 [==============================] - 104s 266ms/step - loss: 1.6877 - acc: 0.6343 - val_loss: 3.3947 - val_acc: 0.2272\n",
            "Epoch 27/50\n",
            "391/390 [==============================] - 105s 270ms/step - loss: 1.6516 - acc: 0.6459 - val_loss: 3.2380 - val_acc: 0.2693\n",
            "Epoch 28/50\n",
            "391/390 [==============================] - 98s 250ms/step - loss: 1.6461 - acc: 0.6463 - val_loss: 3.2189 - val_acc: 0.2732\n",
            "Epoch 29/50\n",
            "391/390 [==============================] - 104s 265ms/step - loss: 1.6182 - acc: 0.6606 - val_loss: 3.1525 - val_acc: 0.2746\n",
            "Epoch 30/50\n",
            "391/390 [==============================] - 92s 236ms/step - loss: 1.6201 - acc: 0.6579 - val_loss: 3.1951 - val_acc: 0.2403\n",
            "Epoch 31/50\n",
            "391/390 [==============================] - 83s 212ms/step - loss: 1.6056 - acc: 0.6606 - val_loss: 3.1032 - val_acc: 0.3463\n",
            "Epoch 32/50\n",
            "391/390 [==============================] - 75s 192ms/step - loss: 1.5999 - acc: 0.6594 - val_loss: 3.3281 - val_acc: 0.2863\n",
            "Epoch 33/50\n",
            "391/390 [==============================] - 82s 209ms/step - loss: 1.5753 - acc: 0.6673 - val_loss: 2.9735 - val_acc: 0.3303\n",
            "Epoch 34/50\n",
            "391/390 [==============================] - 80s 204ms/step - loss: 1.5814 - acc: 0.6666 - val_loss: 3.2185 - val_acc: 0.2540\n",
            "Epoch 35/50\n",
            "391/390 [==============================] - 82s 211ms/step - loss: 1.5500 - acc: 0.6797 - val_loss: 3.2689 - val_acc: 0.3181\n",
            "Epoch 36/50\n",
            "391/390 [==============================] - 81s 207ms/step - loss: 1.5364 - acc: 0.6832 - val_loss: 3.1239 - val_acc: 0.2951\n",
            "Epoch 37/50\n",
            "391/390 [==============================] - 81s 206ms/step - loss: 1.5213 - acc: 0.6885 - val_loss: 3.2070 - val_acc: 0.2709\n",
            "Epoch 38/50\n",
            "391/390 [==============================] - 81s 207ms/step - loss: 1.5146 - acc: 0.6886 - val_loss: 3.1489 - val_acc: 0.2969\n",
            "Epoch 39/50\n",
            "391/390 [==============================] - 80s 205ms/step - loss: 1.5046 - acc: 0.6909 - val_loss: 3.5382 - val_acc: 0.2303\n",
            "Epoch 40/50\n",
            "391/390 [==============================] - 76s 194ms/step - loss: 1.4946 - acc: 0.6937 - val_loss: 3.1507 - val_acc: 0.2804\n",
            "Epoch 41/50\n",
            "391/390 [==============================] - 81s 208ms/step - loss: 1.4720 - acc: 0.6971 - val_loss: 3.3611 - val_acc: 0.2663\n",
            "Epoch 42/50\n",
            "391/390 [==============================] - 59s 152ms/step - loss: 1.4694 - acc: 0.6969 - val_loss: 3.6152 - val_acc: 0.2743\n",
            "Epoch 43/50\n",
            "391/390 [==============================] - 58s 148ms/step - loss: 1.4644 - acc: 0.7040 - val_loss: 3.1871 - val_acc: 0.3528\n",
            "Epoch 44/50\n",
            "391/390 [==============================] - 57s 147ms/step - loss: 1.4399 - acc: 0.7063 - val_loss: 3.4358 - val_acc: 0.2926\n",
            "Epoch 45/50\n",
            "391/390 [==============================] - 58s 148ms/step - loss: 1.4615 - acc: 0.6984 - val_loss: 3.0262 - val_acc: 0.3359\n",
            "Epoch 46/50\n",
            "391/390 [==============================] - 57s 146ms/step - loss: 1.4273 - acc: 0.7112 - val_loss: 3.4603 - val_acc: 0.2841\n",
            "Epoch 47/50\n",
            "391/390 [==============================] - 57s 146ms/step - loss: 1.4212 - acc: 0.7134 - val_loss: 3.2178 - val_acc: 0.3326\n",
            "Epoch 48/50\n",
            "391/390 [==============================] - 57s 147ms/step - loss: 1.4107 - acc: 0.7161 - val_loss: 2.9589 - val_acc: 0.3418\n",
            "Epoch 49/50\n",
            "391/390 [==============================] - 56s 144ms/step - loss: 1.3882 - acc: 0.7189 - val_loss: 3.1726 - val_acc: 0.3244\n",
            "Epoch 50/50\n",
            "391/390 [==============================] - 58s 148ms/step - loss: 1.4113 - acc: 0.7118 - val_loss: 3.0231 - val_acc: 0.3218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-549f4e627b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m                     validation_data = (x_test,y_test))\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nhp3wKLVNC6R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}