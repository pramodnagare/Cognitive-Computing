{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EXPERIMENT+3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NsJnmrcNBKsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2016
        },
        "outputId": "2a0bb7f1-0123-447e-b614-d3b22987f153"
      },
      "cell_type": "code",
      "source": [
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Conv2D, MaxPooling2D, Dense, Flatten,Dropout,Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import SGD \n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "\n",
        "print('Shape of training dataset :',x_train.shape)\n",
        "print('Shape of testing dataste :' ,x_test.shape)\n",
        "\n",
        "#formatting the dataset \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),activation = 'relu' ,input_shape=[32,32,3]))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip = False)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) / 32, epochs=50,\n",
        "                    validation_data = (x_test,y_test))\n",
        "\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 48s 0us/step\n",
            "Shape of training dataset : (50000, 32, 32, 3)\n",
            "Shape of testing dataste : (10000, 32, 32, 3)\n",
            "Epoch 1/50\n",
            "1563/1562 [==============================] - 47s 30ms/step - loss: 1.8550 - acc: 0.3042 - val_loss: 2.3183 - val_acc: 0.1904\n",
            "Epoch 2/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.6633 - acc: 0.3883 - val_loss: 2.4418 - val_acc: 0.1796\n",
            "Epoch 3/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.5982 - acc: 0.4148 - val_loss: 2.4313 - val_acc: 0.1310\n",
            "Epoch 4/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.5584 - acc: 0.4318 - val_loss: 2.3802 - val_acc: 0.1613\n",
            "Epoch 5/50\n",
            "1563/1562 [==============================] - 43s 27ms/step - loss: 1.5391 - acc: 0.4410 - val_loss: 2.3876 - val_acc: 0.1605\n",
            "Epoch 6/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.5188 - acc: 0.4531 - val_loss: 2.4564 - val_acc: 0.1375\n",
            "Epoch 7/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.5022 - acc: 0.4607 - val_loss: 2.4537 - val_acc: 0.1571\n",
            "Epoch 8/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4956 - acc: 0.4627 - val_loss: 2.5110 - val_acc: 0.1261\n",
            "Epoch 9/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4805 - acc: 0.4657 - val_loss: 2.4459 - val_acc: 0.1675\n",
            "Epoch 10/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4798 - acc: 0.4693 - val_loss: 2.4897 - val_acc: 0.1491\n",
            "Epoch 11/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4792 - acc: 0.4682 - val_loss: 2.4446 - val_acc: 0.1527\n",
            "Epoch 12/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4771 - acc: 0.4726 - val_loss: 2.4511 - val_acc: 0.1448\n",
            "Epoch 13/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4625 - acc: 0.4775 - val_loss: 2.3371 - val_acc: 0.1756\n",
            "Epoch 14/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4601 - acc: 0.4769 - val_loss: 2.4071 - val_acc: 0.1513\n",
            "Epoch 15/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4570 - acc: 0.4809 - val_loss: 2.4268 - val_acc: 0.1458\n",
            "Epoch 16/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4627 - acc: 0.4799 - val_loss: 2.3385 - val_acc: 0.1884\n",
            "Epoch 17/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4474 - acc: 0.4836 - val_loss: 2.4637 - val_acc: 0.1326\n",
            "Epoch 18/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4489 - acc: 0.4840 - val_loss: 2.5589 - val_acc: 0.1078\n",
            "Epoch 19/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4525 - acc: 0.4830 - val_loss: 2.4735 - val_acc: 0.1470\n",
            "Epoch 20/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4423 - acc: 0.4850 - val_loss: 2.4746 - val_acc: 0.1510\n",
            "Epoch 21/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4534 - acc: 0.4845 - val_loss: 2.4690 - val_acc: 0.1633\n",
            "Epoch 22/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4519 - acc: 0.4847 - val_loss: 2.4380 - val_acc: 0.1798\n",
            "Epoch 23/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4452 - acc: 0.4841 - val_loss: 2.4336 - val_acc: 0.1355\n",
            "Epoch 24/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4458 - acc: 0.4820 - val_loss: 2.4219 - val_acc: 0.1779\n",
            "Epoch 25/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4383 - acc: 0.4871 - val_loss: 2.5029 - val_acc: 0.1414\n",
            "Epoch 26/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4455 - acc: 0.4844 - val_loss: 2.4929 - val_acc: 0.1258\n",
            "Epoch 27/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4349 - acc: 0.4879 - val_loss: 2.4598 - val_acc: 0.1409\n",
            "Epoch 28/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4361 - acc: 0.4891 - val_loss: 2.4624 - val_acc: 0.1366\n",
            "Epoch 29/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4397 - acc: 0.4885 - val_loss: 2.3439 - val_acc: 0.1990\n",
            "Epoch 30/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4449 - acc: 0.4919 - val_loss: 2.3887 - val_acc: 0.1631\n",
            "Epoch 31/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4429 - acc: 0.4885 - val_loss: 2.6255 - val_acc: 0.1363\n",
            "Epoch 32/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4419 - acc: 0.4873 - val_loss: 2.4245 - val_acc: 0.1427\n",
            "Epoch 33/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4403 - acc: 0.4881 - val_loss: 2.4307 - val_acc: 0.1447\n",
            "Epoch 34/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4354 - acc: 0.4921 - val_loss: 2.3924 - val_acc: 0.1741\n",
            "Epoch 35/50\n",
            "1563/1562 [==============================] - 43s 27ms/step - loss: 1.4332 - acc: 0.4903 - val_loss: 2.4298 - val_acc: 0.1498\n",
            "Epoch 36/50\n",
            "1563/1562 [==============================] - 43s 27ms/step - loss: 1.4335 - acc: 0.4914 - val_loss: 2.4412 - val_acc: 0.1417\n",
            "Epoch 37/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4340 - acc: 0.4911 - val_loss: 2.3697 - val_acc: 0.1663\n",
            "Epoch 38/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4361 - acc: 0.4901 - val_loss: 2.3882 - val_acc: 0.1689\n",
            "Epoch 39/50\n",
            "1563/1562 [==============================] - 43s 27ms/step - loss: 1.4311 - acc: 0.4904 - val_loss: 2.3627 - val_acc: 0.1649\n",
            "Epoch 40/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4324 - acc: 0.4946 - val_loss: 2.4522 - val_acc: 0.1555\n",
            "Epoch 41/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4378 - acc: 0.4889 - val_loss: 2.4272 - val_acc: 0.1732\n",
            "Epoch 42/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4272 - acc: 0.4958 - val_loss: 2.3533 - val_acc: 0.1774\n",
            "Epoch 43/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4384 - acc: 0.4886 - val_loss: 2.3929 - val_acc: 0.1888\n",
            "Epoch 44/50\n",
            "1563/1562 [==============================] - 43s 27ms/step - loss: 1.4343 - acc: 0.4919 - val_loss: 2.4443 - val_acc: 0.1471\n",
            "Epoch 45/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4315 - acc: 0.4917 - val_loss: 2.3987 - val_acc: 0.1538\n",
            "Epoch 46/50\n",
            "1563/1562 [==============================] - 44s 28ms/step - loss: 1.4395 - acc: 0.4866 - val_loss: 2.3635 - val_acc: 0.1864\n",
            "Epoch 47/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4348 - acc: 0.4911 - val_loss: 2.4276 - val_acc: 0.1562\n",
            "Epoch 48/50\n",
            "1563/1562 [==============================] - 43s 28ms/step - loss: 1.4227 - acc: 0.4940 - val_loss: 2.3801 - val_acc: 0.1814\n",
            "Epoch 49/50\n",
            "1563/1562 [==============================] - 43s 27ms/step - loss: 1.4345 - acc: 0.4880 - val_loss: 2.3955 - val_acc: 0.1800\n",
            "Epoch 50/50\n",
            "1563/1562 [==============================] - 43s 27ms/step - loss: 1.4348 - acc: 0.4900 - val_loss: 2.4608 - val_acc: 0.1626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-146a5b48cf71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "iP75DpuRBVX4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}