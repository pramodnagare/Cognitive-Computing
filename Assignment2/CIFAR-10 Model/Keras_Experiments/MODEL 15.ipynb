{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EXPERIMENT+15.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "chFwcd8_MZIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1983
        },
        "outputId": "78e8598b-0c9e-47f0-9a49-b7e1de1da107"
      },
      "cell_type": "code",
      "source": [
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import  Conv2D, MaxPooling2D, Dense, Flatten,Dropout,Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from keras import regularizers\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import SGD \n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
        "\n",
        "print('Shape of training dataset :',x_train.shape)\n",
        "print('Shape of testing dataste :' ,x_test.shape)\n",
        "\n",
        "#formatting the dataset \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),input_shape=[32,32,3],kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.0005),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(256,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(256,(3,3),kernel_regularizer=regularizers.l2(0.0005),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(512,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(512,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(512,(3,3),kernel_regularizer=regularizers.l2(0.0003),padding='same'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "#model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "SGD = SGD(lr=1.0, decay=1e-6, momentum=0.9)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='SGD',metrics=['accuracy'])\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip = False)\n",
        "\n",
        "# compute quantities required for featurewise normalization\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) /256, epochs=50,\n",
        "                    validation_data = (x_test,y_test))\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of training dataset : (50000, 32, 32, 3)\n",
            "Shape of testing dataste : (10000, 32, 32, 3)\n",
            "Epoch 1/50\n",
            "196/195 [==============================] - 72s 369ms/step - loss: 3.6337 - acc: 0.1958 - val_loss: 4.3978 - val_acc: 0.1000\n",
            "Epoch 2/50\n",
            "196/195 [==============================] - 61s 310ms/step - loss: 2.8593 - acc: 0.2581 - val_loss: 4.3159 - val_acc: 0.1005\n",
            "Epoch 3/50\n",
            "196/195 [==============================] - 59s 303ms/step - loss: 2.6901 - acc: 0.2889 - val_loss: 5.1317 - val_acc: 0.1000\n",
            "Epoch 4/50\n",
            "196/195 [==============================] - 60s 308ms/step - loss: 2.5671 - acc: 0.3297 - val_loss: 3.9677 - val_acc: 0.1707\n",
            "Epoch 5/50\n",
            "196/195 [==============================] - 60s 306ms/step - loss: 2.5024 - acc: 0.3404 - val_loss: 3.9327 - val_acc: 0.1127\n",
            "Epoch 6/50\n",
            "196/195 [==============================] - 60s 307ms/step - loss: 2.4509 - acc: 0.3669 - val_loss: 4.1608 - val_acc: 0.1106\n",
            "Epoch 7/50\n",
            "196/195 [==============================] - 59s 302ms/step - loss: 2.3898 - acc: 0.3791 - val_loss: 4.0435 - val_acc: 0.1082\n",
            "Epoch 8/50\n",
            "196/195 [==============================] - 55s 278ms/step - loss: 2.3604 - acc: 0.4008 - val_loss: 4.2504 - val_acc: 0.1457\n",
            "Epoch 9/50\n",
            "196/195 [==============================] - 59s 301ms/step - loss: 2.3291 - acc: 0.4112 - val_loss: 4.0904 - val_acc: 0.1073\n",
            "Epoch 10/50\n",
            "196/195 [==============================] - 59s 300ms/step - loss: 2.3018 - acc: 0.4263 - val_loss: 4.1244 - val_acc: 0.1000\n",
            "Epoch 11/50\n",
            "196/195 [==============================] - 60s 309ms/step - loss: 2.2645 - acc: 0.4354 - val_loss: 3.5611 - val_acc: 0.1769\n",
            "Epoch 12/50\n",
            "196/195 [==============================] - 61s 310ms/step - loss: 2.2284 - acc: 0.4480 - val_loss: 3.7135 - val_acc: 0.1561\n",
            "Epoch 13/50\n",
            "196/195 [==============================] - 60s 305ms/step - loss: 2.2050 - acc: 0.4515 - val_loss: 3.7347 - val_acc: 0.1468\n",
            "Epoch 14/50\n",
            "196/195 [==============================] - 60s 308ms/step - loss: 2.2151 - acc: 0.4514 - val_loss: 3.6771 - val_acc: 0.1256\n",
            "Epoch 15/50\n",
            "196/195 [==============================] - 59s 301ms/step - loss: 2.1750 - acc: 0.4673 - val_loss: 3.7525 - val_acc: 0.1286\n",
            "Epoch 16/50\n",
            "196/195 [==============================] - 55s 281ms/step - loss: 2.1283 - acc: 0.4952 - val_loss: 4.0282 - val_acc: 0.1485\n",
            "Epoch 17/50\n",
            "196/195 [==============================] - 60s 307ms/step - loss: 2.1210 - acc: 0.4791 - val_loss: 3.6555 - val_acc: 0.1537\n",
            "Epoch 18/50\n",
            "196/195 [==============================] - 59s 299ms/step - loss: 2.0910 - acc: 0.4931 - val_loss: 3.6219 - val_acc: 0.1459\n",
            "Epoch 19/50\n",
            "196/195 [==============================] - 60s 307ms/step - loss: 2.0877 - acc: 0.4984 - val_loss: 4.0623 - val_acc: 0.1368\n",
            "Epoch 20/50\n",
            "196/195 [==============================] - 59s 299ms/step - loss: 2.0616 - acc: 0.5081 - val_loss: 4.0806 - val_acc: 0.1281\n",
            "Epoch 21/50\n",
            "196/195 [==============================] - 60s 304ms/step - loss: 2.0259 - acc: 0.5226 - val_loss: 3.6193 - val_acc: 0.1856\n",
            "Epoch 22/50\n",
            "196/195 [==============================] - 60s 306ms/step - loss: 2.0354 - acc: 0.5206 - val_loss: 3.5502 - val_acc: 0.1860\n",
            "Epoch 23/50\n",
            "196/195 [==============================] - 58s 294ms/step - loss: 1.9908 - acc: 0.5383 - val_loss: 3.9039 - val_acc: 0.1239\n",
            "Epoch 24/50\n",
            "196/195 [==============================] - 55s 283ms/step - loss: 1.9866 - acc: 0.5351 - val_loss: 4.2589 - val_acc: 0.1359\n",
            "Epoch 25/50\n",
            "196/195 [==============================] - 61s 311ms/step - loss: 1.9536 - acc: 0.5478 - val_loss: 3.7574 - val_acc: 0.1895\n",
            "Epoch 26/50\n",
            "196/195 [==============================] - 64s 328ms/step - loss: 1.9613 - acc: 0.5461 - val_loss: 3.6300 - val_acc: 0.1859\n",
            "Epoch 27/50\n",
            "196/195 [==============================] - 63s 324ms/step - loss: 1.9527 - acc: 0.5443 - val_loss: 3.7456 - val_acc: 0.1757\n",
            "Epoch 28/50\n",
            "196/195 [==============================] - 61s 313ms/step - loss: 1.9284 - acc: 0.5491 - val_loss: 3.7289 - val_acc: 0.1537\n",
            "Epoch 29/50\n",
            "196/195 [==============================] - 63s 319ms/step - loss: 1.9389 - acc: 0.5520 - val_loss: 3.7260 - val_acc: 0.1564\n",
            "Epoch 30/50\n",
            "196/195 [==============================] - 56s 286ms/step - loss: 1.9195 - acc: 0.5625 - val_loss: 3.6442 - val_acc: 0.1767\n",
            "Epoch 31/50\n",
            "196/195 [==============================] - 55s 283ms/step - loss: 1.8866 - acc: 0.5681 - val_loss: 4.1560 - val_acc: 0.1163\n",
            "Epoch 32/50\n",
            "196/195 [==============================] - 57s 291ms/step - loss: 1.8835 - acc: 0.5652 - val_loss: 3.5043 - val_acc: 0.1889\n",
            "Epoch 33/50\n",
            "196/195 [==============================] - 61s 311ms/step - loss: 1.8760 - acc: 0.5711 - val_loss: 3.7435 - val_acc: 0.2031\n",
            "Epoch 34/50\n",
            "196/195 [==============================] - 62s 316ms/step - loss: 1.8446 - acc: 0.5845 - val_loss: 3.4354 - val_acc: 0.1955\n",
            "Epoch 35/50\n",
            "196/195 [==============================] - 63s 323ms/step - loss: 1.8232 - acc: 0.5942 - val_loss: 3.5277 - val_acc: 0.1750\n",
            "Epoch 36/50\n",
            "196/195 [==============================] - 63s 321ms/step - loss: 1.8421 - acc: 0.5893 - val_loss: 3.6141 - val_acc: 0.2161\n",
            "Epoch 37/50\n",
            "196/195 [==============================] - 63s 322ms/step - loss: 1.8265 - acc: 0.5879 - val_loss: 3.6623 - val_acc: 0.1981\n",
            "Epoch 38/50\n",
            "196/195 [==============================] - 62s 316ms/step - loss: 1.8019 - acc: 0.5969 - val_loss: 3.3955 - val_acc: 0.3049\n",
            "Epoch 39/50\n",
            "196/195 [==============================] - 63s 322ms/step - loss: 1.8042 - acc: 0.5939 - val_loss: 3.6554 - val_acc: 0.1792\n",
            "Epoch 40/50\n",
            "196/195 [==============================] - 60s 308ms/step - loss: 1.7897 - acc: 0.6044 - val_loss: 3.8656 - val_acc: 0.2297\n",
            "Epoch 41/50\n",
            "196/195 [==============================] - 64s 324ms/step - loss: 1.7707 - acc: 0.6057 - val_loss: 3.6706 - val_acc: 0.2216\n",
            "Epoch 42/50\n",
            "196/195 [==============================] - 63s 321ms/step - loss: 1.7729 - acc: 0.6067 - val_loss: 3.5127 - val_acc: 0.2395\n",
            "Epoch 43/50\n",
            "196/195 [==============================] - 62s 314ms/step - loss: 1.7428 - acc: 0.6164 - val_loss: 3.5175 - val_acc: 0.1461\n",
            "Epoch 44/50\n",
            "196/195 [==============================] - 62s 318ms/step - loss: 1.7570 - acc: 0.6140 - val_loss: 3.5275 - val_acc: 0.2250\n",
            "Epoch 45/50\n",
            "196/195 [==============================] - 61s 312ms/step - loss: 1.7273 - acc: 0.6217 - val_loss: 3.5428 - val_acc: 0.2438\n",
            "Epoch 46/50\n",
            "196/195 [==============================] - 62s 317ms/step - loss: 1.7169 - acc: 0.6296 - val_loss: 3.6996 - val_acc: 0.2134\n",
            "Epoch 47/50\n",
            "196/195 [==============================] - 63s 323ms/step - loss: 1.7122 - acc: 0.6239 - val_loss: 3.7241 - val_acc: 0.2355\n",
            "Epoch 48/50\n",
            "196/195 [==============================] - 61s 314ms/step - loss: 1.7134 - acc: 0.6314 - val_loss: 3.2942 - val_acc: 0.2375\n",
            "Epoch 49/50\n",
            "196/195 [==============================] - 63s 319ms/step - loss: 1.6916 - acc: 0.6339 - val_loss: 3.6330 - val_acc: 0.2500\n",
            "Epoch 50/50\n",
            "196/195 [==============================] - 63s 320ms/step - loss: 1.6788 - acc: 0.6366 - val_loss: 3.7022 - val_acc: 0.2493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-99f1d04dbff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m                     validation_data = (x_test,y_test))\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gM5y0qg6M8Ij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}